{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8641d94-36bd-4803-82bf-54004fe77e81",
   "metadata": {},
   "source": [
    "# 의사결정나무 모델 (Decision Tree Model)\n",
    "\n",
    "- 데이터를 특정 기준에 따라 분할하고 트리구조를 구성해 데이터를 분류/회귀\n",
    "- 장점 :\n",
    "  - 굉장히 직관적이고, 트리 모델 학습의 구조를 이해하기가 쉽다\n",
    "  - 비모수데이터(정규성을 따르지 않는 형태의 데이터, 이상치가 많은 데이터)에서도 잘 작동 / 전처리가 용이함\n",
    "  - 데이터 개수에도 영향이 적다 / 대용량 데이터에 대해서 매우 잘 작동\n",
    "\n",
    "- 단점 :\n",
    "  - 과적합 Overfitting이 매우 쉽게 잘 발생 / 하이퍼파라미터 튜닝이 필수적\n",
    "  - 분류 경계에서 오류 발생의 가능성이 높다\n",
    " \n",
    "- Tree 구조 :\n",
    "  - Node : 데이터를 특정 기준에 따라 분할하는 역할\n",
    "  - Depth : 각 Node가 특정 조건에 대해 분할 되며 발생하는 층\n",
    "  - Leaf (Terminal Node) : 분할이 모두 끝난 뒤, 맨 아래층 (더이상 분할이 불가능한) Node\n",
    "  - Branch : Root Node부터 맨 아래 Leaf의 하나의 분류 기준들이 있는 줄기\n",
    "\n",
    "- Tree 최적화 기법 : 데이터를 잘 분할 시킬 수 있게끔 계산하는 최적화 알고리즘\n",
    "  - Gini (불순도) : 데이터가 얼마나 섞여있지 않고 순도 높게 유지되는지에 대한 지표\n",
    "    - Gini 높다 : 불순물이 많다 -> 데이터가 섞여 있는 상태\n",
    "    - Gini 낮다 : 순도가 높다 -> 데이터가 명확히 분류되어 있는 상태\n",
    "  - Entropy (무질서도) : 데이터의 무질서 정도를 나타내는 지표 (로그함수)\n",
    "    - Entropy 낮다 : 질서 정연한 상테 / 에너지가 많이 들이지 않아도 되는 상태 (이미 에너지가 들어가서 질서 정연했으니 에너지 더 들일 필요XX)\n",
    "    - Entropy 높다 : 무질서한 상태 / 에너지가 많이 들어가야 하는 상태\n",
    " \n",
    "  - Log Loss : 분류에서의 손실함수를 이용해 데이터가 얼마나 잘 분류됐는지를 계산하는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "689a8d58-20ea-469c-8b2d-6491bd4d5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.express as express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "892417b8-09d2-4133-897a-9ebc2eec956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26283, 25)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26283 entries, 0 to 26282\n",
      "Data columns (total 25 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   방송Code    26283 non-null  float64\n",
      " 1   채널        26283 non-null  object \n",
      " 2   소요분       26283 non-null  float64\n",
      " 3   가중분       26283 non-null  float64\n",
      " 4   방송구분      26283 non-null  object \n",
      " 5   프로그램명     26283 non-null  object \n",
      " 6   상품ID      26283 non-null  int64  \n",
      " 7   상품명       26283 non-null  object \n",
      " 8   매입과세구분    26283 non-null  object \n",
      " 9   상품목표취급금액  26283 non-null  int64  \n",
      " 10  상품목표주문금액  26283 non-null  int64  \n",
      " 11  판매단가      26283 non-null  int64  \n",
      " 12  수수료율      26283 non-null  float64\n",
      " 13  상품주문수량    26283 non-null  int64  \n",
      " 14  상품주문금액    26283 non-null  int64  \n",
      " 15  상품취소수량    26283 non-null  int64  \n",
      " 16  상품취소금액    26283 non-null  int64  \n",
      " 17  ARS금액     26283 non-null  int64  \n",
      " 18  매입형태      26283 non-null  object \n",
      " 19  배송방식      26283 non-null  object \n",
      " 20  상품소요분     26283 non-null  float64\n",
      " 21  상품가중분     26283 non-null  float64\n",
      " 22  상품방송순번    26283 non-null  int64  \n",
      " 23  방송시작시간    26283 non-null  object \n",
      " 24  방송종료시간    26283 non-null  object \n",
      "dtypes: float64(6), int64(10), object(9)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\UserK\\Desktop\\Ranee\\data\\ML\\14_Data.csv')\n",
    "print(df1.shape)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978bc87c-74eb-46c5-917b-43e19d97b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c70511f8-a653-4ccd-aa7b-11e4363a2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #\n",
    "from sklearn.pipeline import make_pipeline # 파이프라인 구성\n",
    "from sklearn.compose import make_column_transformer # 분할처리 때 필요(병렬로 배치)\n",
    "\n",
    "from sklearn.impute import SimpleImputer # 결측값 처리\n",
    "from sklearn.preprocessing import MinMaxScaler # 스케일링\n",
    "from sklearn.preprocessing import OneHotEncoder # 인코딩\n",
    "\n",
    "from imblearn.combine import SMOTEENN # 불균형데이터처리\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # 교차검증&매개변수 튜닝\n",
    "from sklearn.metrics import classification_report # 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d53585af-2373-4b5b-9f6f-d234c4ecdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['방송연도'] = pd.to_datetime(df1['방송시작시간']).dt.year\n",
    "df1['방송월'] = pd.to_datetime(df1['방송시작시간']).dt.month\n",
    "df1['방송일'] = pd.to_datetime(df1['방송시작시간']).dt.day\n",
    "df1['방송요일'] = pd.to_datetime(df1['방송시작시간']).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8fd14d8-073f-471d-b1f4-fa8db164e6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "목표달성여부\n",
       "1.0    16333\n",
       "0.0     9950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['목표달성액'] =   df1['상품목표주문금액'] - df1['상품주문금액']\n",
    "cond1 = df1['목표달성액'] > 0\n",
    "df1.loc[cond1, '목표달성여부'] = 1\n",
    "df1.loc[~cond1, '목표달성여부'] = 0\n",
    "df1['목표달성여부'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81af4748-82fa-4182-92cc-211d9caf791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['소요분','방송구분','판매단가','ARS금액','수수료율','방송요일','방송월']]\n",
    "Y = df1['목표달성여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbe59d77-203e-4337-92cf-f9b0b3b4b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a44025c3-a864-4c8f-adcd-76fadd936e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자는 문자끼리, 숫자는 숫자끼리 처리될수있도록 식별할 수 있게, 문자숫자 이름 리스트를 구성\n",
    "numeric_list = X.describe().columns\n",
    "category_list = X.describe(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35973ecf-bfa9-4844-b29f-b717daa44d1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTEENN()' (type <class 'imblearn.combine._smote_enn.SMOTEENN'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m prepro_pipe \u001b[38;5;241m=\u001b[39m make_column_transformer((numeric_pipe,numeric_list),(category_pipe,category_list))\n\u001b[0;32m      5\u001b[0m model_pipe \u001b[38;5;241m=\u001b[39m make_pipeline(prepro_pipe, SMOTEENN(), DecisionTreeClassifier())\n\u001b[1;32m----> 6\u001b[0m model_pipe\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:339\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps)\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_steps()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;66;03m# Setup the memory\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     memory \u001b[38;5;241m=\u001b[39m check_memory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:230\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    228\u001b[0m         t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     ):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll intermediate steps should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers and implement fit and transform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor be the string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, \u001b[38;5;28mtype\u001b[39m(t))\n\u001b[0;32m    235\u001b[0m         )\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    239\u001b[0m     estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTEENN()' (type <class 'imblearn.combine._smote_enn.SMOTEENN'>) doesn't"
     ]
    }
   ],
   "source": [
    "# 전처리 파이프를 구성\n",
    "numeric_pipe = make_pipeline(SimpleImputer(strategy='median'), MinMaxScaler())\n",
    "category_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "prepro_pipe = make_column_transformer((numeric_pipe,numeric_list),(category_pipe,category_list))\n",
    "model_pipe = make_pipeline(prepro_pipe, SMOTEENN(), DecisionTreeClassifier())\n",
    "model_pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf03aa-6e37-493c-b5e6-b204b0761785",
   "metadata": {},
   "source": [
    "- Tree Model Hyper-Parameter\n",
    "  - criterion : 분류 최적화 알고리즘 선택 ('gini','entropy','log_loss')\n",
    "  - **max_depth** : 트리의 최대 깊이를 제한 (기본값 None / 모두 분류가 될 때 까지 층을 형성)\n",
    "  - **min_samples_split** : 노드를 분할 하기 위한 최소 데이터 수 (기본값 2) \n",
    "  - **min_samples_leaf** : Leaf 노드가 갖는 최소 데이터 수\n",
    "  - class_weight : 클래스의 가중치를 부여할지 말지에 대한 매개변수 (None / 'balanced\n",
    "  - max_lead_nodes : 최대 노드 수를 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0152757-2a74-48d1-b59a-4d85b7448643",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {'decisiontreeclassifier__criterion' : ['gini','entropy'], # 2\n",
    "                  'decisiontreeclassifier__max_depth' : range(5,20), # 15\n",
    "                  'decisiontreeclassifier__class_weight' : [None,'balanced'], # 2\n",
    "                  'decisiontreeclassifier__min_samples_leaf' : [20,50,100]} # 3\n",
    "\n",
    "grid_model = GridSearchCV(model_pipe, param_grid=hyperparameter, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_model.fit(X_train,Y_train)\n",
    "best_model = grid_model.bset_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e5761-42e9-460e-8c4b-acc2c6a3f182",
   "metadata": {},
   "source": [
    "- Feature Importance (변수 중요도)\n",
    "  - 분류를 수행함에 있어, 각 X가 얼마나 분류에 기여하였는가\n",
    "  - 회귀분석의 회귀계수와는 개념이 다르다!\n",
    "  - 변수중요도가 높다고 해서 Y값이 직접적으로 변하지는 않음 (습도가 8일때 분류가 잘되었다고 해서 습도가 Y값에 가장중요한건 아님. 습도가 8일때가 중요한거지)\n",
    "  - 어떤 인자가 중요한지 찾기 위해 트리구조를 만들었다? 이건 안됨 -> 이 인자가 중요하네요~유의할필요가있습니다 라고 까지는 표현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd44edd-848f-4640-bb74-41b1b3cfb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame()\n",
    "df_importance['X'] = best_modle[0].get_feature_name_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572595d-8b28-4ab1-82d1-b3c73202f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance['importance'] = best_model['decisiontreeclassifier'].feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
