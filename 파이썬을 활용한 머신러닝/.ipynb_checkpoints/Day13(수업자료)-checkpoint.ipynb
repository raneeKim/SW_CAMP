{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ef0b07-8053-4f22-bdc3-0241d857ce5e",
   "metadata": {},
   "source": [
    "# Ensemble \n",
    "\n",
    "1. 보팅 (Voting) : 여러가지 다른 모델의 예측을 결합하여 최종 예측을 만드는 기법 / 주로 분류 문제에서 사용되며 각 개별 모델의 가중치를 부여하거나 단순한 투표로써 최종 예측을 수행\n",
    "2. 배깅 (Bagging, Bootstrap Aggregating) :  Bootstrap Sampling을 통해, 여러 개별 모델을 생성하고, 이 모델들 예측의 평균이나 다수결 투표등을 결합하여 최종 예측\n",
    "3. 부스팅 (Boosting) : 약한 학습모델 (Weak Leanear)를 순차적으로 학습시켜 강력한 하나의 모델을 구성. 이전 모델이 잘 못 예측한 Sample에 가중치를 두며 다음 모델이 더 잘 예측되도록 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb123dc-8b2d-4206-8ee6-a56d6b345a4d",
   "metadata": {},
   "source": [
    "**Boosting Model**\n",
    "\n",
    "1. Ada Boosting (Adptive Boosting): 이전에 학습의 결과에서 잘 반영되지 않은 데이터에 대해 가중치를 부여하여 복원 추출을 수행\n",
    "   - 앞서 분류를 적절히 수행하지 못한 데이터에 대해 계속 가중을 주어 학습 성능을 향상\n",
    "   - 데이터에 이상치가 존재하는 경우, 이상치에 대해 계속 가중치가 부여되며 학습\n",
    "   - 사전에 구성한 데이터가 깔끔하지 않다면(이상치가 많은 데이터), 지속적인 학습에 대해 성능개선이 이뤄지지 않음\n",
    "   - 앞서 분류된 결과에 대해 가중치가 학습이 진행 되며 소실되는 현상이 발생\n",
    "\n",
    "2. Gradient Boosting : 이상치가 있거나 너무 높게 부여된 Weight에 대해 주변 데이터가 오분류 될 가능성을 극복하고자, 분류 결과에 가중치를 부여할 때 마다 Weight에 의한 모델의 오차가 최소가되는 방향으로(최소제곱법) 오분류 값을 학습하는 방식\n",
    "   - Ada Boosting 모델 보다 더 오차에 민감한 모델을 구성\n",
    "   - 복원추출된 데이터에 대해 만들어진 모델을 오차를 계산하는 수식을 넣어 모델의 성능을 높이는 형태\n",
    "   - 시간이 매우 오래 소요가 됨 (최소제곱법에 의한 최적화 기법을 사용) \n",
    "   - 순차적 학습이 진행되기 때문에, 나중에 학습된 모델에 대해 **과적합 현상**이 발생\n",
    "   - **하이퍼파라미터 튜닝**이 필수적 \n",
    "\n",
    "3. XGboosting : GB 모델에서 과적합 되는 현상을 방지하기 위해, 최소제곱법 최적화 수식에 규제항을 추가하여, 과적합을 방지하는 형태로 학습\n",
    "   - 복원 추출한 데이터의 오차가 줄어들게 끔 학습을 하다보면 분류 구조가 매우 복잡해 질 수 있음\n",
    "   - 이를 방지하기 위해 **규제항**을 추가하여 과적합을 방지\n",
    "   - 속도가 느리다 / 하이퍼파라미터 튜닝이 필수적\n",
    "\n",
    "4. Light Boosting : **Boosting** 계열 알고리즘의 자원 소요에 대한 부하를 줄이고자, 복원 추출되는 데이터의 양을 조절하는 알고리즘을 활용해, 계산의 량을 줄여 빠른 속도로 학습이 수행 되게끔 학습\n",
    "    - 대용량 데이터 (특성이 복잡한 데이터 -> Column 수가 많은)에 대해 절약된 자원(시간 + 메모리)으로 학습 을 수행\n",
    "    - 다소 정확도가 떨어질 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124dd48-58a2-403c-8d98-f27c9ec85bda",
   "metadata": {},
   "source": [
    "**Ada Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12300c2-46a7-43e6-aee2-448ceabb93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import plotly.express as px \n",
    "import scipy.stats as stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15024b-e77f-4429-abdb-a13ee82c4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('18_Customer_data.csv', encoding='cp949')\n",
    "print(df1.shape)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8a4b76-d0fc-424b-9c3b-8d3ce5e1b84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    5161\n",
       "1    1702\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Target'] = df1['고객이탈여부'].replace({'No':0, 'Yes':1})\n",
    "df1['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f7baa9-c88b-465a-8882-11228909b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df1['Target']\n",
    "X = df1[['성별', '연령', '결혼여부', '부양자수', '보안서비스', '백업서비스',\n",
    "         '데이터무제한','과금방식','데이터사용료', '로밍사용료']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036e4d14-7082-446e-8385-27e9b45ec169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # 학습 데이터와 검증 데이터 분할\n",
    "from sklearn.pipeline import make_pipeline # 특성공학 처리 프로세스 구축\n",
    "from sklearn.compose  import make_column_transformer # 병렬로 파이프라인 구축 \n",
    "from sklearn.impute   import SimpleImputer # 결측값을 대치 \n",
    "from sklearn.preprocessing import MinMaxScaler # 스케일링 \n",
    "from sklearn.preprocessing import OneHotEncoder # 인코딩 \n",
    "from sklearn.ensemble import AdaBoostClassifier # Ada Boosting 모델로 학습 \n",
    "from sklearn.model_selection import GridSearchCV # 교차 검증 및 하이퍼파라미터 튜닝\n",
    "from sklearn.metrics import classification_report # 분류모델 성능 평가 \n",
    "import pickle # 생성된 모델을 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddce8bd8-569d-4226-9c5a-4fe165dc24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cf82ed-c678-4dd9-99ec-266152197b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1 = ['성별','결혼여부', '보안서비스', '백업서비스', '데이터무제한', '과금방식']\n",
    "data_list2 = ['연령']\n",
    "data_list3 = ['데이터사용료', '로밍사용료']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652829d0-74fe-408e-b665-1b546aaa0120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder()) # 문자 파이프\n",
    "pipe2 = make_pipeline(SimpleImputer(strategy='mean')) # 숫자 1 (연령만 처리)\n",
    "pipe3 = make_pipeline(SimpleImputer(strategy='median'), MinMaxScaler()) # 숫자 2 (금액 관련) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d537456-1ab1-43a9-9b0a-c27bdffb36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_pipe = make_column_transformer((pipe1, data_list1), \n",
    "                                      (pipe2, data_list2), \n",
    "                                      (pipe3, data_list3))\n",
    "model_pipe  = make_pipeline(prepro_pipe, AdaBoostClassifier()) #  데이터 전처리 + 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e135adca-6c0b-4d54-a108-ea8c512c2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1644b-6acb-456f-979e-cc99a8b4a788",
   "metadata": {},
   "source": [
    "**Ada Boosting Hyperparameter** \n",
    "- Tree 알고리즘을 이용해 학습 / Max Depth = 1  모델을 반복해서 학습\n",
    "- n_estimators : 부스팅이 종료되는 학습 모델(DT)의 최대 숫자 지정 / 완벽한 분류가 발생 할 시, 조기에 학습이 종료 / n_estimators = 200\n",
    "- learning_rate : 각 부스팅의 반복에서 각 DT에 적용되는 가중치 /  learning_rate가 높으면, 각 모델의 기여도가 증대 / (learning_rate <-> n_estimators / Trade Off )\n",
    "    - learning_rate를 늘리면, 완벽하게 분류될 estimators 학습 기의 개수가 많지 않아도 완벽하게 조기에 분류가 됨\n",
    "    - n_estimators를 늘리면, learning_rate가 높지 않더라도 충분하게 분류될 수 있는 모델을 구성\n",
    "- algorithm : Ada 부팅 알고리즘 내 최적화 함수\n",
    "  - SAMME (Stagewise Additive Modeling using a Multicalss Expoential loss Function) : 약한 학습 기들을 반복적으로 학습 시키며, 학습기의 성능에 따라 Sample의 가중치를 조절\n",
    "  - SAMME.R : SAMME에서 신뢰도 지표를 기반으로 가중치를 부여 / 더 세밀한 성능 향상/조절 / 속도 저하\n",
    "  - SAMME.R : 약한 학습긱가 클래스의 확률를 추정할 때 사용 / SAMME  확률 추정을 따로 수행하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65176ec1-385a-491c-972e-49614c3595e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 + 하이퍼 파라미터 튜닝 \n",
    "hyperparameter = {'adaboostclassifier__n_estimators':[100, 500],\n",
    "                 'adaboostclassifier__learning_rate':[0.01, 0.1, 1, 1.5],\n",
    "                 'adaboostclassifier__algorithm':['SAMME','SAMME.R']} \n",
    "grid_model = GridSearchCV(model_pipe, param_grid=hyperparameter, \n",
    "                          cv=3, scoring='f1',n_jobs=-1)\n",
    "grid_model.fit(X_train, Y_train)\n",
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd841003-9151-40a1-9972-0c06c1b0bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 생성 \n",
    "def eval_func(model):\n",
    "    Y_train_pred = model.predict(X_train)\n",
    "    Y_test_pred  = model.predict(X_test)\n",
    "    print('학습 성능')\n",
    "    print(classification_report(Y_train, Y_train_pred))\n",
    "    print('일반화 성능')\n",
    "    print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53742f18-f41e-4a9b-868b-bf6617e1257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_func(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb956cd-4365-4122-ad98-6fb92764d025",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b78a29-d96f-4b1d-aaa7-0ac565b7f91b",
   "metadata": {},
   "source": [
    "- Gradient Boosting Parameter \n",
    "\n",
    "- subsample : 학습에 수행되는 Sub Sample의 비율 (전체 Train Set 대비 비율) \n",
    "- n_iter_no_change : 검증 성능이 개선되지 않을 때, 훈련을 조기에 종료할지 말지 결정 \n",
    "(횟수, 지정된 횟수만큼 성능이 개선되지 않는다면, 학습을 중단)\n",
    "- validation_fraction : 조기종료를 위해 훈련 데이터(Train Set) 내에서 Validation Set의 비율\n",
    "- max_depth : 각 개별 DT 학습기의 Depth 를 설정 / min_sample_split / min_sample_leaf ...\n",
    "- min_impurity_decrease : 불순도의 특정 임계값을 지정하여, 이 값보다 큰 경우에만 트리를 분할  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa6a52f-ac43-45e6-b18e-35cc95c0f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35329abb-3d2e-40a1-82c8-9be9c0a69bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe2 = make_pipeline(prepro_pipe, GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e89114-37be-4bff-bc3b-7b2eae7fe7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {'gradientboostingclassifier__n_estimators':[100,500],\n",
    "                 'gradientboostingclassifier__max_depth':[5, 15],\n",
    "                 'gradientboostingclassifier__n_iter_no_change':[5],\n",
    "                 'gradientboostingclassifier__validation_fraction':[0.2],\n",
    "                 'gradientboostingclassifier__learning_rate':[0.01, 0.1, 1, 1.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6a1388-7e7c-4105-b029-bd13120f83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model2= GridSearchCV(model_pipe2, param_grid=hyperparameter, \n",
    "                          cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_model2.fit(X_train, Y_train)\n",
    "best_model2 = grid_model2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dc7745a-5261-441a-a75f-15b1d5825693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_func(best_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1a2928-54da-4833-820f-9539fa39a08c",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c216232-36d4-447d-916b-7ef284921afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e5982c3-e1b5-4a99-956f-35664c1fdf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a47f4379-d6e2-4e87-b936-e971b6ff4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe3 = make_pipeline(prepro_pipe, XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab970b7b-8a97-43e8-bb8f-0dbed454acdf",
   "metadata": {},
   "source": [
    "**XGB Parameter**\n",
    "\n",
    "- reg_alpha  : L1 규제를 위한 가중치 \n",
    "- reg_lambda : L2 규제를 위한 가중치\n",
    "- scale_pos_weight : 클래스 불균형 (Imbalanced Data) 조절하기 위한 가중치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54132844-9495-4a68-87b6-12fbee87396c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CONET-02\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [11:24:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"leanring_rate\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "hyperparameter = {'xgbclassifier__n_estimators':[100, 1000],\n",
    "                 'xgbclassifier__leanring_rate':[0.01, 0.1, 1, 1.5],\n",
    "                 'xgbclassifier__max_depth':[5,15],\n",
    "                 'xgbclassifier__reg_alpha':[0.01, 0.1, 1, 1.5],\n",
    "                 'xgbclassifier__reg_lambda':[0.01, 0.1, 1, 1.5]}\n",
    "grid_model3 = GridSearchCV(model_pipe3, param_grid=hyperparameter, \n",
    "                           cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_model3.fit(X_train, Y_train)\n",
    "best_model3 = grid_model3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4988108-017a-438f-8f26-8855154706ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_func(best_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47af14-cd73-48b2-82b5-d070e5bf0204",
   "metadata": {},
   "source": [
    "# Stacking Model \n",
    "\n",
    "- 여러 가지 모델을 이용해, 데이터의 예측값을 계산하여, 해당 예측값을 X로 , 실제값을 Y로 구성해, 최종 Meta 모델의 학습데이터로 사용하는 앙상블 기법\n",
    "    - Model1 학습 -> 예측값1\n",
    "    - Model2 학습 -> 예측값2\n",
    "    - Model3 학습 -> 예측값3\n",
    "    - 예측값1, 예측값2, 예측값3 -> X로 / Y  => Meta Model 예측 실시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e488e35-d97d-4ec9-900d-c4bdea72a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 만들었던 Model (Ada Boosting / GB / XGB ) 이용하여 Stacking Ensemble 구성 \n",
    "df_meta_train = pd.DataFrame()\n",
    "# Ada Boosting 모델의 X_train 데이터에 대한 이탈 확률 값 \n",
    "df_meta_train['Ada'] = pd.DataFrame(best_model.predict_proba(X_train))[1]\n",
    "# Gradient Boosting 모델의 X_train 데이터에 대한 이탈 확률 값\n",
    "df_meta_train['GB']  = pd.DataFrame(best_model2.predict_proba(X_train))[1]\n",
    "# XGB 모델의 X_train 데이터에 대한 이탈 확률 값\n",
    "df_meta_train['XGB'] = pd.DataFrame(best_model3.predict_proba(X_train))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcdd6676-f3d7-4800-af90-d02303e71eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_test = pd.DataFrame()\n",
    "df_meta_test['Ada'] = pd.DataFrame(best_model.predict_proba(X_test))[1]\n",
    "df_meta_test['GB']  = pd.DataFrame(best_model2.predict_proba(X_test))[1]\n",
    "df_meta_test['XGB'] = pd.DataFrame(best_model3.predict_proba(X_test))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc80a1a2-0967-4e5f-acec-e4c35c20b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed649a50-8830-4d3a-a561-3bfa851243e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = RandomForestClassifier() \n",
    "grid_meta = GridSearchCV(meta_model, \n",
    "                         param_grid={'n_estimators':[100,1000], 'max_depth':[5, 15]},\n",
    "                         cv=3, n_jobs=-1, scoring='f1')\n",
    "grid_meta.fit(df_meta_train, Y_train)\n",
    "best_model = grid_meta.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b045312-04a8-4e85-94f7-aeb8eb14092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_meta_pred = best_model.predict(df_meta_train)\n",
    "Y_test_meta_pred  = best_model.predict(df_meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95c3e9ff-46b9-47b8-bad3-bab9bf7a9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(Y_train, Y_train_meta_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02875feb-bfb3-49ba-a9fa-49a09c86e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(Y_test, Y_test_meta_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254638df-2911-4d1e-96e0-e58aca95305d",
   "metadata": {},
   "source": [
    "# 비지도 학습 \n",
    "\n",
    "- X들 간의 관계(유사성, 거리, ...)을 이용해, 비슷한 데이터를 묶거나, 연관 있는 데이터를 찾거나, 차원을 줄이거나 하는등의 학습 기법\n",
    "    - 1. 군집 분석 (Clustering)\n",
    "    - 2. 연관 규칙 (Association Analysis)\n",
    "    - 3. 차원 축소 (Dimensionality Reduction)\n",
    "    - 4. 이상 탐지 (Anomaly Detection) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fc5ba-db4d-44e2-b2a3-da980e0b445f",
   "metadata": {},
   "source": [
    "**군집 분석**\n",
    "\n",
    "- 데이터 간 거리를 계산하여, 인접한 데이터를 묶어주는 기법\n",
    "    - 군집 분석 이후에, 나눠진 군집들에 대한 특성을 시각화나 가설검정 등으로 파악 -> Insight 도출\n",
    "    - 군집 분석을 통해, 데이터의 라벨을 생성 -> 생성된 라벨을 Y로 , 나머지 X를 이용해 분류 모델\n",
    "- 종류\n",
    "    - 계층형 군집분석 : 병합 또는 분할 기법을 이용하여, 가깝거나 멀리 떨어진 데이터들을 묶어나가거나 분할 해 나가며 군집을 형성하는 분석기법 \n",
    "    - 비계층형 군집분석 : 데이터 간의 기하 거리, 밀도, 분포 등을 이용하여 군집을 형성하는 기법  \n",
    "    - 잠재공간 군집분석 : 분포 추정을 통해 잠재 공간 (Latent Space)계산된 추정치를 이용하여 군집을 형성 (범주형)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d92cf3-7d70-456f-bbcd-0312de72c234",
   "metadata": {},
   "source": [
    "- **계층형 군집 분석**\n",
    "  - 1. 병합형 군집 분석 : 각 데이터 포인트를 하나의 클러스터로 간주한 뒤, 유사한 클러스터 끼리 묶어 나가며 병합하는 방식\n",
    "  - 2. 분할형 군집 분석 : 모든 데이터를 하나의 군집으로 간주한 뒤, 서로 다른 특징을 가진 데이터를 나눠 가며 군집을 분할하는 방식  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4941c7-9744-424b-b1f2-1ba90da80144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('19_Data.csv')\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7eb5a9-12ec-4b92-a2ec-45d479993f16",
   "metadata": {},
   "source": [
    "- **Parameter**\n",
    "\n",
    "- n_cluster : 군집의 개수를 지정 / 기본값 2\n",
    "- metric : 클러스터 간의 거리를 측정하는 방법 / 기본값 euclidean\n",
    "  - \"euclidean\" : 저차원 데이터에서 잘 작동 (X의 개수가 적은)\n",
    "  - \"manhattan\" : 저차원 데이터에서 잘 작동\n",
    "  - \"cosine\" : 고차원 데이터에서 잘 작동\n",
    "- linkage : 클러스터를 병합하는 기법을 선택\n",
    "  - ward\n",
    "    - 같은 군집 내의 데이터들 간의 분산을 최소화 하는 방식으로 클러스터를 병합\n",
    "    - 군집 내 응집도(Cohesion)를 최대화 하면서, 군집간의 분리도(Separation)를 최대화하는것을 목표   \n",
    "  - complete\n",
    "    - 두 군집 간의 가장 먼 거리를 이용하여 클러스터를 병합\n",
    "    - 두 개의 클러스터 간의 모든 데이터 포인트들 중에서 가장 먼 거리를 갖는 데이터를 이용해 병합\n",
    "    - 군집 간의 거리가 점점 멀어지게 끔 군집이 형성 -> 군집간의 명확한 차이를 강조할 때 \n",
    "  - average\n",
    "    - 두 군집 간의 평균 거리를 이용하여 군집을 병합\n",
    "    - 데이터들 간의 평균 거리가 가장 작아지는 포인트를 찾아서 병합을 수행\n",
    "    - 데이터 간의 평균 거리를 이용해 병합 -> 군집 간 균형잡힌 거리적인 특성이 도출        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ca6645c-7a7a-470d-957d-59c3d5828542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층형 병합 군집분석 \n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "883bae39-e5b3-4859-b7c8-c99e3ecaa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(columns=['LOT', 'WAFER']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5819e5fa-f46d-4617-a478-35ee25622b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=3)\n",
    "df2['Target'] = cluster.fit_predict(df2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ea5e96b-c7d6-45a0-8b77-f1a750d93fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1944f774-fe06-42df-91dc-fda644c580de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.scatter_matrix : AttributeError: 'DataFrame' object has no attribute 'iteritems' Error \n",
    "pd.DataFrame.iteritems = pd.DataFrame.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ac21d-9ae3-4b2f-81b1-bcfcc7018293",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_matrix(df2.iloc[0:100], dimensions=['Y1','Y2','Y3'], color='Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355e893-2bea-4929-a3b8-3841c01fb0db",
   "metadata": {},
   "source": [
    "# 비계층형 군집 분석 \n",
    "\n",
    "- 클러스터 간의 계층 구조를 형성하지 않고 군집을 만들어내는 모든 종류의 군집분석 기법\n",
    "- 군집을 묶는 속도가 비교적 빠르다 / 직관적 \n",
    "- K-mean / DBSCAN / Mean Shift... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc6342-4a17-461a-a920-a13f2109994f",
   "metadata": {},
   "source": [
    "- **K-Means Clustering**\n",
    "\n",
    "- 주어진 K개 (사용자가 지정하는 K개수)만큼 군집을 형성, 군집 중심점을 기준으로 특정 범위 내 가까운 데이터들을 묶어나가며 군집을 형성\n",
    "- 알고리즘 절차\n",
    "  - 1. 중심점 초기화 : K개의 군집 중심점을 임의로 선택(알고리즘에 의해 선택) / 초기 지점 선택\n",
    "    2. 할당 : 초기 중심점을 기준으로 일정 거리 이내 (유클리드 거리) 가까운 데이터들을 같은 군집으로 병합\n",
    "    3. 할당 된 군집들 내 데이터로 새로운 군집 중심점을 계산\n",
    "    4. 새로 계산 된 군집 중심점을 기준으로 다시 특정 거리 이내 데이터를 병합\n",
    "    5. 앞선 과정을 지속적으로 반복하여, 군집 중심점이 더 이상 움직이지 않을 때 까지 반복\n",
    "\n",
    "- 주의사항 :\n",
    "  - 초기 중심점의 선택에 따라 알고리즘 수렴에 영향을 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf168a0-11ca-42ab-8b63-69e2f1934854",
   "metadata": {},
   "source": [
    "- **Parameter**\n",
    "  - n_cluster : 클러스터의 개수를 사용자가 지정\n",
    "  - init : 초기 중심점 선택 방법을 지정\n",
    "    - \"k-means++\" (기본값) / \"random\" : 이상치가 많거나, 범주형 데이터가 존재하는 경우  \n",
    "  - max_iter : 최대 반복 횟수 / 군집 중심점을 최대 몇번 까지 옮겨서 군집을 구성할 것인가에 대한 지표 / 기본 값 300\n",
    "  - algorithm : K-Means 알고리즘 내 최적화 작동 방식\n",
    "    - 'full' : 클러스터링을 수행하면서, 군집 중심점을 업데이트 할 때 마다 모든 데이터 포인트와 군집 중심점 간의 거리를 계산 / 데이터 셋이 큰 경우 -> 시간 소요가 큼\n",
    "    - 'elkan' : 각 클러스터와 모든 데이터 포인트 사이의 거리를 미리 계산하여, 군집 중심점을 업데이트 할 때마다 발생하는 계산을 줄이는 방식\n",
    "    - 'auto' : 데이터 크기에 따라 알고리즘이 적절한 방식을 선택 / 1000개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "753ecd68-0d48-4d03-8838-02ade9e3c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907288cd-936f-4393-82a4-22891853fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2  = KMeans(n_clusters=3, max_iter=500 )\n",
    "df2['Target2'] = cluster2.fit_predict(df2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c6bbb8b-4c71-4e97-9f8c-805c23f23ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.scatter_matrix(df2.iloc[0:100], dimensions=['Y1', 'Y2', 'Y3'], color='Target2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2575-b2d1-4bdb-96cd-61cf614a0711",
   "metadata": {},
   "source": [
    "- 군집분석 -> 비지도 학습 / 사용자가 몇 개의 군집을 구성 할 것 인가 직접 선택\n",
    "- 그럼에도 군집화가 잘 수행되었는가 평가를 할 때\n",
    "\n",
    "- **Silhouette Score (실루엣 분석)**\n",
    "  - 군집 내 같은 데이터들 끼리 얼마나 모였는지에 대한 응집력과 서로 다른 군집끼리 얼마나 떨어져 있는가에 대한 분리력을 수식으로 계산\n",
    "  - Silhouette Score : -1 ~ +1 사이의 값이 도출\n",
    "    - 1 에 가까울수록 높은 응집력/ 높은 분리력 군집\n",
    "    - 0 에 가까울수록 군집 간 경계가 모호, 중첩 / 낮은 응집력, 낮은 분리력\n",
    "    - 음수 값은 일반적으로 잘못된 클러스터링 상태 (모든 군집의 데이터가 섞여 있는 상태)\n",
    "  - 참고 지표로 사용 (비지도 학습) -> \"평가\" 지표이나, 지표가 낮다고 해서 사용을 못하지는 않는다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3db16c0a-9a4d-49b5-9d2b-4b0560c0a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46409594-7e51-4728-b1cc-f26979ae1752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3277953087827936"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(df2.drop(columns=['Target', 'Target2']) ,\n",
    "                 df2['Target']) # 계층형 군집분석으로 3집단 군집화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02d24199-8e85-4595-8190-66ca278fa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3764454986934112"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(df2.drop(columns=['Target', 'Target2']) ,\n",
    "                 df2['Target2']) # K-means군집분석으로 3집단 군집화 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
