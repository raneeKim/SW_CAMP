{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8b73f8-5584-471b-82e4-0f215bba7d1a",
   "metadata": {},
   "source": [
    "# 단어 표현 \n",
    "\n",
    "- One Hot Encoding : 텍스트 마이닝 이전, 단어를 Matrix 형태로 표현 \n",
    "- CBOW : 텍스트 마이닝 이전, 단어를 Matrix 형태로 표현\n",
    "- Skip-Gram : 주변 단어에 대한 예측 및 유사도 계산\n",
    "\n",
    "## TF-IDF (Term Frequence Inverse Document Frequency)\n",
    "\n",
    "- CBOW 방식을 보완하기 위해 개별 문서나, 문장에 자주 나타는 단어에 가중치를 두되, 전체적으로 많이 등장하는 단어에는 패널티를 부여해 확률 값으로 단어를 표현\n",
    "- 특정 문장에서 많이 등장하는 단어는 중요한 단어가 되지만, 다른 문장에서도 많이 사용한다면, 범용적으로 사용되는 단어일 가능성이 높음\n",
    "- 각 문장의 특징을 더 명확하게 구분 짓는 기법 -> 텍스트 마이닝 (분류) 높은 성능을 발휘 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0554476a-16d6-4072-a918-48c898c18f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\" 아무리 우겨봐도 어쩔 수 없네\n",
    "저기 개똥 무덤이 내 집인걸\n",
    "가슴을 내밀어도 친구가 없네\n",
    "노래하던 새들도 멀리 날아가네\n",
    "가지 마라 가지 마라 가지 말아라\n",
    "나를 위해 한 번만 노래를 해주렴\n",
    "나나 나나나나 쓰라린 가슴 안고\n",
    "오늘 밤도 그렇게 울다 잠이 든다\n",
    "\n",
    "마음을 다 주어도 친구가 없네\n",
    "사랑하고 싶지만 마음뿐인걸\n",
    "나는 개똥벌레 어쩔 수 없네\n",
    "손을 잡고 싶지만 모두 떠나가네\n",
    "가지 마라 가지 마라 가지 말아라\n",
    "나를 위해 한 번만 손을 잡아주렴\n",
    "아아 외로운 밤 쓰라린 가슴 안고\n",
    "오늘 밤도 그렇게 울다 잠이 든다\n",
    "울다 잠이 든다\n",
    "울다 잠이 든다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f3f997-6d8f-4384-9e08-06a7a2df9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0e1730-7377-4f57-bea3-77a7a6b914a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()\n",
    "sent1 = kkma.sentences(text1) # 하나의 문단을 문장으로 분해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac82098c-3e7d-4df3-93bd-c27a52eca37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "x = tfidf_model.fit_transform(sent1) # TF-IDF 기법으로 해석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4388ecf-f345-4b27-8b7d-c2bb5a2dbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feature = tfidf_model.get_feature_names_out() # 각 문장의 단어를 분해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf169c7-1f1c-42ed-9488-c97e93a7eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tfidf = x.toarray() # 각 문장별 단어의 확률 값을 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a00f9b-e467-4d01-af59-d1b2c1fbc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb8b50-9710-48c9-abde-0c00673e4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=word_tfidf, columns=word_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392c2a3-1de1-427b-b9ed-0db0f441585c",
   "metadata": {},
   "source": [
    "# 문장 표현 (Sentence Representation)\n",
    "- 텍스트 분류 및 연관분석 등, 텍스트 마이닝 기법을 사용하기 전, 문장단위의 표현 방법\n",
    "- Text to Sequence : 여러 문장을 컴퓨터가 이해 할 수 있는 Sequence로 표현\n",
    "- Padding : 변환된 Sequence를 똑같은 형태로( Column의 수를 지정)하여 변환하는 작업  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db854647-0d80-48df-b029-09e0ba4d530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업의 한줄평을 X / 기업추천여부 Y  -> 분류 모델 생성 (Text Mining + 문장 표현) \n",
    "df1 = pd.read_csv('24_Data.csv')\n",
    "df2 = df1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf9122-36d1-49f0-a1e0-b2906a7b4b19",
   "metadata": {},
   "source": [
    "**Text to Sequence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "685f23b4-5042-493e-9f37-1910ebbf6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a88c7105-6ade-43ab-8f34-f73b3edc852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_model = Tokenizer()\n",
    "token_model.fit_on_texts(df2['기업한줄평']) # 기업 한줄 평 내 모든 단어 토큰을 하나의 정수로 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a37400ec-0a85-4d04-8915-8279a3eae83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"부서 by 부서, 팀장 by 팀장으로 근무환경이 달라지는 곳\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['기업한줄평'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdd50998-27b5-4f57-86b6-c3e1d33ef1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 29, 28, 87, 29, 88, 89, 90, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_seq = token_model.texts_to_sequences(df2['기업한줄평']) # 텍스트를 매칭된 숫자로 변환 \n",
    "text_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e39246e-198c-40b4-b002-3f3df4695f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_model.word_index # 어떤 문자가 어떤 숫자로 매칭 되었는가 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d864-7f72-45ba-b948-a0a98ba610f2",
   "metadata": {},
   "source": [
    "**Padding**\n",
    "- 텍스트 길이에 따라 Sequence 길이가 달라지는데, 이 서로다른 길이를 0으로 채워 나눠진 문장을 일정한 크기의 Matrix 표현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebdd7c60-3deb-458a-b8a8-aad9202b17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a442723-e25a-4e00-8779-0b16c629eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(text_seq, maxlen=50, padding='post')\n",
    "# pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a018e89-d4e8-4da9-b263-18ac0e17eed1",
   "metadata": {},
   "source": [
    "**Text Mining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0580c2c-1c96-488a-9f43-e627f0c006e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Target'] = df2['기업추천여부'].replace({'추천':1, '비추천':0})\n",
    "df2['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92979a19-d1d9-4e29-861c-c6b574c987bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['기업한줄평']\n",
    "Y = df2['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7262917b-77e7-43fd-bdc0-4eecb78266c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f78f745-937a-4ccf-b0ee-e72ace5d94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbf22b58-ac54-4e1c-bcd9-1e4e81179c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인을 구성하여, Text to Seq / Padding 수행 \n",
    "# 특정 데이터를 전처리하는 함수를 생성해 파이프라인 안에 넣어 처리 \n",
    "def text_preprocessing(X):\n",
    "    token_model = Tokenizer()\n",
    "    token_model.fit_on_texts(X) # 입력 받은 X로 단어 사전을 구성 \n",
    "    seq_x = token_model.texts_to_sequences(X) # 입력 받은 X 문자가 Seq 형태로 변환\n",
    "    return pad_sequences(seq_x, maxlen=20, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ba54326-42a6-4c9e-b1bf-628d716598ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 직접 생성한 전처리 함수를 PipeLine 내에서 사용할 수 있게 변환 \n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f86d017-84be-4eff-8dcc-63272ef41450",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_token_tranfer  = FunctionTransformer(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8709ab9-6ba0-4e56-b8ae-98a87c141a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프 라인을 구성하여 학습 \n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling  import SMOTE\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble        import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c4aa88f-1321-4e67-9b00-ab90f1e48daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파이프라인을 구성 \n",
    "model_pipe = make_pipeline(text_token_tranfer, MinMaxScaler(), \n",
    "                           SMOTE(), RandomForestClassifier() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e9f6764-688c-4745-a629-60ab775020cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 및 하이퍼파라미터 튜닝 \n",
    "hyper_list = {'randomforestclassifier__max_depth':[5,10,15,20],\n",
    "              'randomforestclassifier__min_samples_split':range(5,10),\n",
    "              'randomforestclassifier__criterion':['gini','entropy']}\n",
    "gird_model = GridSearchCV(model_pipe, param_grid=hyper_list, \n",
    "                          cv=3, scoring='f1', n_jobs=-1)\n",
    "gird_model.fit(X_train, Y_train)\n",
    "best_model = gird_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a440358-7bf8-4220-a7a2-56b8f4c697fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad520fe6-47aa-4f28-9c30-59744609a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = best_model.predict(X_train)\n",
    "Y_test_pred  = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20a581-0731-45f6-8431-b32ad0285a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065d82b-5fbb-49c0-af16-6fd628f33f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec1de67e-d12e-4ddc-aeb3-0c4e890eadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 입력 \n",
    "new_Data = \"회사의 협력적 관계에 있어서 가장 중요한건 팀워크입니다만?ㅋㅋ 우리회산 그게 잘 안되는 듯 ㅋㅋ\"\n",
    "input_data = pd.DataFrame(data=[new_Data], columns=['기업한줄평'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f5053-baf1-4759-8020-890acf291ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(input_data) # 기업 추천 여부 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8799eab2-6cc6-4cce-9455-5060be4c7f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25236905, 0.74763095]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba(input_data) # 기업 추천 여부 확률을 예측 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce7a0c-347a-4677-a941-a66877feaaa0",
   "metadata": {},
   "source": [
    "# 신경망 알고리즘을 이용한 자연어 처리 \n",
    "\n",
    "## RNN (Recurrent Neural Network / 순환신경망 알고리즘)\n",
    "- 순서를 갖는 Sequence 데이터를 처리 / 현재 까지 처리된 정보 상태(State) 저장하여, 앞/뒤 정보를 유지하며 학습을 수행\n",
    "    - ![image.png](https://wikidocs.net/images/page/22886/rnn_image3.5.PNG)\n",
    "    - 1. 문장 표현 Sequence가 순차적으로 Node에 들어감\n",
    "    - 2. 각 Node가 선행 단어부터 순차적으로 처리 -> 앞서 처리된 단어의 결과를 이용해, 다음층으로 보낼 가중치를 계산\n",
    "    - 3. 각 단어의 위치에서 Layer(Node)통과한 결과가 출력\n",
    "\n",
    "- 특징 :\n",
    "  - 데이터의 순서와 서열을 반영하여 학습\n",
    "  - 장기 의존성 문제 (Long Term Dependencies) : 시퀀스가 길어지면, 이전에 처리된 정보가 점점 학습이 진행되며 손실\n",
    "    - Gradient 소실 / 폭주 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78158e9c-b047-4383-9c00-ee2d3adf0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Embedding \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6f0d7c1-5b4a-4405-92cd-6114ba680ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rnn = text_preprocessing(X_train)\n",
    "X_test_rnn = text_preprocessing(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51f88c-f33a-4528-bad1-c6d8a11a2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN = Sequential()\n",
    "model_RNN.add(Embedding(10000, 8))\n",
    "model_RNN.add(SimpleRNN(32))\n",
    "model_RNN.add(Dense(1, activation='sigmoid'))\n",
    "model_RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_RNN.fit(X_train_rnn, Y_train, epochs=20, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87445435-8555-4278-88fa-cc36dc2137fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(result):\n",
    "    if result >= 0.5 : return 1 \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6bb7e216-3a92-4ba8-85e2-dbd2c353a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = pd.Series(model_RNN.predict(X_train_rnn).flatten()).apply(func1)\n",
    "Y_test_pred  = pd.Series(model_RNN.predict(X_test_rnn ).flatten()).apply(func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8020c1-3c3b-4e9e-bdce-3067476a819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355c927-d005-4bcf-af62-ce2eb5ba3355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,  Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f2302-e8eb-447b-ad70-f16f24067434",
   "metadata": {},
   "source": [
    "# LSTM (Long Short-Term Memory) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8ae4f-5075-45e8-9348-17beae6f32c1",
   "metadata": {},
   "source": [
    "- RNN 모델의 장기의존문제를 해결하기 위해 고안된 RNN 계열의 모델\n",
    "- ![img3](https://wikidocs.net/images/page/22888/vaniila_rnn_and_different_lstm_ver2.PNG)\n",
    "- Seq의 길이가 긴 데이터에 대해 Cell State라는 Node를 활용하여, 장기적으로 정보가 전달 될 수 있도록 정보를 저장 하는 Node를 추가한 형태\n",
    "- LSTM은 Cell State를 조정하기 위해 세가지 주요 Gate(입력값이 처리되는 Filter)를 사용\n",
    "  - 1. Input Gate (입력 게이트) : Cell State에 새로운 정보를 저장할지 말지를 결정\n",
    "       - 하나는 Sigmoid 함수로 구성 -> 어떤 값을 Update 할 지를 결정\n",
    "       - 다른 하나는 Tanh 함수로 구성 -> Cell State에 추가될 후보 값들을 생성\n",
    "       - ![imge1](https://wikidocs.net/images/page/22888/inputgate.PNG)\n",
    "  - 2. Forget Gate (삭제 게이트) : Cell State에서 어떤 정보를 제거할 지 결정\n",
    "       - 현재 Input(입력)과 이전 Node에 있는 State 중 Sigmoid를 이용하여, 0과 1사이 값을 출력\n",
    "       - 1 : 정보를 유지 / 0 : 정보를 삭제\n",
    "       - ![imge1](https://wikidocs.net/images/page/22888/forgetgate.PNG)\n",
    "  - 3. Output Gate (출력 게이트) : Cell State의 정보를 기반으로 어떤 값을 출력할지를 결정\n",
    "       - Sigmoid 함수를 이용해 어떤 Cell State를 출력할지 결정하고, Cell State는 Tanh를 통과하여 값의 범위를 조정한 뒤 Sigmoid Node와 합쳐져 최종 출력을 계산\n",
    "       - ![imge2](https://wikidocs.net/images/page/22888/outputgateandhiddenstate.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5ba1992-7799-4d37-befd-e43c47ff643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b419d-5a69-4dcc-a408-524318521ab0",
   "metadata": {},
   "source": [
    "- Drop Out : 신경망을 학습할 때, 과적합 현상을 방지하기 위한 규제 방법 / 일정 비율의 Node에 대한 Weight Update를 비활성화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a74718-d3f9-4131-ae56-d594fc3b265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM = Sequential()\n",
    "model_LSTM.add( Embedding(10000, 8))\n",
    "model_LSTM.add( LSTM(128, dropout=0.2 ))\n",
    "model_LSTM.add( Dense(1, activation='sigmoid'))\n",
    "model_LSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_LSTM.fit(X_train_rnn, Y_train, epochs=20, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "50787081-5872-4bf4-bb82-7e5652a27bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = pd.Series(model_LSTM.predict(X_train_rnn).flatten()).apply(func1)\n",
    "Y_test_pred  = pd.Series(model_LSTM.predict(X_test_rnn ).flatten()).apply(func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a8268a-93c1-42c0-a5a4-65b74ab14c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7674c4-ecc0-4394-bfd9-e8e26ceb41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,  Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8fbdd-d6d8-482c-8852-9130d0081957",
   "metadata": {},
   "source": [
    "# GRU (Gated Recurrent Unit)\n",
    "- LSTM 의 변형 형태로, LSTM 모델의 3가지 게이트 구조를 단순화하여 효율적인 계산 (시간과 자원)\n",
    "- ![img4](https://wikidocs.net/images/page/22889/gru.PNG)\n",
    "\n",
    "- Update Gate : 현재 계산된 State값을 다음 Node에 얼마나 반영할 지를 계산\n",
    "    - LSTM 모델에 Input Gate 와 Forget Gate을 수행\n",
    "    - 과거의 정보를 얼마나 유지하고, 다음 정보를 전달할지를 결정 \n",
    "- Reset Gate : 이전에 Node에서 전달받은 State가 현재의 입력값과 함께 어떻게 연산 될지를 결정\n",
    "      - LSTM에 Cell State 없이, 과거의 정보를 효과적으로 필터링\n",
    "- LSTM 알고리즘과 비교했을 때, 더 적은 Parameter(Layer, Node, Time)로 잘 작동 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80465f17-adfb-446e-946d-3b1ddbf18b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8530ea-e55f-48c7-803c-367bc3e80643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = Sequential()\n",
    "model_GRU.add( Embedding(10000,8))\n",
    "model_GRU.add( GRU(128, dropout=0.2) )\n",
    "model_GRU.add( Dense(1, activation='sigmoid'))\n",
    "model_GRU.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_GRU.fit(X_train_rnn, Y_train, epochs=20, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "31919b94-972a-4fd6-b1e1-d698d4bc4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = pd.Series(model_GRU.predict(X_train_rnn).flatten()).apply(func1)\n",
    "Y_test_pred  = pd.Series(model_GRU.predict(X_test_rnn ).flatten()).apply(func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9ec03-63f3-4587-a318-7a66cc476c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_train, Y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "509dec64-d5fe-49de-81b4-27660d793d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.84      1.00      0.91        16\n",
      "\n",
      "    accuracy                           0.84        19\n",
      "   macro avg       0.42      0.50      0.46        19\n",
      "weighted avg       0.71      0.84      0.77        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CONET-02\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\CONET-02\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\CONET-02\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,  Y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
