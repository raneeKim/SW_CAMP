{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451d49d8-78a5-41e6-ac36-72563468605d",
   "metadata": {},
   "source": [
    "# 알고리즘 (Model) \n",
    "\n",
    "- 최적화 (Optimization) : 문제 상황에서 여러 해결방안 중 최적의 해결 방안을 찾는 것\n",
    "- 기본적으로 머신러닝에서 데이터로부터 학습을 통해 수식화를 진행할 때, 목표값(Y)을 잘 예측하는 수식을 만드는 과정 / 여러개의 수식 중, 해당 데이터에 가장 적절한 수식을 찾는 것 -> 최적화\n",
    "\n",
    "- 수학적 접근 : 특정 함수 값을 최소화(최대화)하는 최적의 수식 Parameter(회귀 계수, Weight, 가중치) 조합을 찾는 문제\n",
    "  - 최소화 Minimization : 함수의 목표변수 Y값이 최소가 되게끔 Parameter를 찾는 문제\n",
    "      - Y : 오류 / 오차 / 비용(Cost) / 손실 / ...  \n",
    "  - 최대화 Maximization : 함수의 목표변수 Y값이 최대가 되게끔 Parameter를 찾는 문제\n",
    "      - Y : 이윤 / 점수 / 성능 / ...\n",
    "\n",
    "- 데이터 마이닝에 적용하여 사용 : 지도학습에서 Model을 구축할 때, **데이터 상의 실제값과 Model이 예측한 예측값의 차이(오차 Error, Residual)** 가 최소가 되는 방향으로 모델을 구성\n",
    "  \n",
    "- 최적화 기법의 종류 :\n",
    "  - Least Square Method (최소 제곱법 - 회귀분석에서의 최적화)\n",
    "  - Gradient Descent Method (경사 하강법 - 회귀분석에서의 최적화)\n",
    "  - Newton's Method\n",
    "  - Gauss Newton's Method\n",
    "  - Bayesain Method\n",
    "  - Markov Batesian Method ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655d9d9-3f6a-4c1e-9bc6-edfa9402d07e",
   "metadata": {},
   "source": [
    "# 최소 제곱법 (Least Square Method) \n",
    "\n",
    "- 회귀분석 사용되는 최적화 기법 (신경망 알고리즘 최적화 기법)\n",
    "- 데이터를 대표하는 회귀선을 찾을 때, 회귀선이 예측한 예측값과 실제 데이터 값의 차이(오차/ 잔차)의 제곱의 합 또는 평균이 최소화가 되는 방향으로 Parameter를 찾는 방법\n",
    "![img](https://raw.githubusercontent.com/Claudiooo/DeepLearningLearning/Group2/Images/linear_regression_error1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ff0bc-df68-4a3a-adb0-40882c550189",
   "metadata": {},
   "source": [
    "- 대수적 기법 : 오차항이 최소가 되는 지점의 m, b (회귀계수)를 찾기 위해 m과 b에 대해 편미분을 실시하여, 오차항의 최소가 되는 지점을 연립방정식을 통해 찾는 방식\n",
    "  ![img](https://spin.atomicobject.com/wp-content/uploads/linear_regression_gradient1.png)\n",
    "\n",
    "- 해석학적 기법 : 오차항을 행렬형태로 표현하여 유사역행렬 (Pseudo Inverse Matrix)을 이용해 회귀 계수 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423eec8b-3d53-4aaf-b326-774b7fe0ae1c",
   "metadata": {},
   "source": [
    "# 경사하강법 (Gradient Descent) \n",
    "\n",
    "- 점진적인 반복 계산을 통해 함수가 최소가 되는 파라미터를 찾는 모든\n",
    "  - Gradient : 함수가 증가하는/감소하는 방향과 크기를 표현\n",
    "  - 오차(실제값과 예측값의 차이)가 최소가 되는 방향으로 (Gradient) 점진적으로 계산 (Descent)\n",
    "  - 1. Weight(회귀 계수) 값을 임의로 지정한 다음 비용함수(Cost Function, 오차항 (y-y')²)를 계산\n",
    "  - 2. 오차항의 차이가 있는경우, Weight(회귀 계수)값을 Update, 다시 비용함수를 계산\n",
    "  - 3. 비용함수가 감소했다면, 2번 절차를 반복하며, 비용함수가 바뀌지 않는 지점까지 반복해서 계산\n",
    "\n",
    "- \n",
    "- **확률적 경사 하강법 (Stochastic Gradient Descent)**\n",
    "- 경사하강법은 모든 데이터에 대해 반복적으로 비용함수(Cost Function)를 계산하기 때문에, 시간이 오래걸림\n",
    "- 전체 데이터가 아닌, 일부분의 데이터를 Random Sampling 하여 Weight에 대한 Update (학습 시간 단축)\n",
    "- Batch : Random하게 Sampling 할 데이터를 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd340551-40d0-4f8a-ad78-a76ef5e989c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy.stats as stats \n",
    "import plotly.express as px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6bf9ac-1acd-4a4d-9b81-24c2baf5468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('12_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf10729-2b73-49b9-9466-e44f1e374bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [x for x in df1.columns if 'Mean' in x][1:] \n",
    "# Mean 글자가 포함된 column명을 호출 하되, \n",
    "# 맨 첫번째 (0번째) Mean Radius는 제외하고 리스트를 구성 \n",
    "# Mean Radius 는 Y로 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c507b3cb-d962-4b6c-95ab-80dfe3ef7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df1['Mean Radius']\n",
    "X = df1[col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226d4015-e03f-46f9-b858-688ef5b85139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # 학습데이터와 검증데이터 분할 \n",
    "from sklearn.pipeline import make_pipeline  # 특성공학 + 학습 \n",
    "from sklearn.preprocessing import StandardScaler # 스케일링 기법 사용 (평균 0 표준편차1)\n",
    "from sklearn.linear_model  import LinearRegression # 최소제곱법 +경사하강법 (회귀분석) \n",
    "from sklearn.model_selection import GridSearchCV # 교차검증 + 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8c2f17-c614-45ee-92d5-d3c82829933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59796e85-2b1b-4de9-b92b-f483a4ba78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링 + 학습 파이프라인 구성 \n",
    "model_pipe = make_pipeline( StandardScaler(), LinearRegression() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b600ac8-9c96-494a-b639-e39505da8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 \n",
    "grid_model = GridSearchCV(model_pipe, param_grid={},cv=5)\n",
    "grid_model.fit(X_train, Y_train) # 학습 수행 \n",
    "best_model = grid_model.best_estimator_ # 학습 후 최적성능 모델 도출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09032995-f2c0-42d4-be07-065006aeeb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.182746478873236"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model['linearregression'].intercept_ # 회귀 모델의 절편을 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b81fee5-8e45-4605-a4a8-c483bf7c4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame()\n",
    "df_coef['coef'] = best_model['linearregression'].coef_ # 회귀 모델의 회귀 계수를 계산\n",
    "df_coef['X'] = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8270ce-8659-4688-929b-d312da6cd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef.sort_values(by='coef') # 각 X 앞에 곱해진 회귀 계수값을 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd3eef-20ef-48c0-be8f-e8919971bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar( , x='X', y='coef') # 회귀 계수 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f31bca30-7839-4b26-a81e-28e0e2ded91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀모델 성능 평가 \n",
    "# R² (결정계수) : 회귀식이 데이터를 얼마나 잘 설명하고 있는가  (0 ~ 1)\n",
    "# MSE (평균 제곱 오차) : 실제 값과 예측값의 차이의 제곱 합의 평균을 계산 (0으로 갈수록 좋은 모델) \n",
    "# MAE (평균 절대 오차) : 실제 값과 예측값의 차이의 절대값의 합의 평균을 계산 (0으로 갈수록 Best) \n",
    "# RMSE : MSE에 Root 제곱근을 사용하여, 더욱 직관적으로 해석 가능한 평가지표 \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6c21e6-6292-4822-b37b-19c512eac66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 모델로 예측값을 계산해, 실제값과 예측값의 차이를 연산 \n",
    "Y_train_pred = best_model.predict(X_train)\n",
    "Y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df60c08e-db8e-409c-8ce4-7e05e02b7049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 결정 계수 0.9994225170133184\n",
      "일반화 결정 계수 0.9991793129574523\n"
     ]
    }
   ],
   "source": [
    "print('학습 결정 계수', r2_score(Y_train, Y_train_pred))\n",
    "print('일반화 결정 계수', r2_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a7286cf-e9b2-4554-968e-068c6b3e42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 MSE  0.00706026698701229\n",
      "일반화 MSE  0.010560016874980838\n"
     ]
    }
   ],
   "source": [
    "print('학습 MSE ', mean_squared_error(Y_train, Y_train_pred))\n",
    "print('일반화 MSE ', mean_squared_error(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b533f18-fcaa-4b32-ad88-16f1ae087ad4",
   "metadata": {},
   "source": [
    "# 다항회귀분석 (Polynominal Regression)\n",
    "\n",
    "- 기존의 선형 회귀 분석 : X와 Y의 관계식,수식이 1차식인 형태\n",
    "- 다항회귀 : 다차원의 X를 2차 또는 3차 방정식 이상으로 표현하여 회귀 분석을 수행\n",
    "- 학습 시키려 하는 X를 Polynominal 변환(파이프라인 내에서 수행)을 통해 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4dd73cf-7e6e-4a92-80a2-1ebd0bee087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "198a8a46-40eb-452b-9bab-90029b884099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20947878-5707-4367-9ddc-7ef3629f554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(PolynomialFeatures(degree=2).fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4397fb7-6fe6-4a7f-a5f6-5d5c96d6970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "model_pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c50fc19-91ab-4753-9897-00e622f3e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipe['linearregression'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e7063-2795-4f58-a66c-1213f88e5911",
   "metadata": {},
   "source": [
    "# 규제 선형 회귀 (Regularization Regression)\n",
    "\n",
    "- Overfitting을 방지하기 위해,(차원의 저주 방지) 회귀 계수를 적절히 통제하여 회귀식을 구성\n",
    "- Cost Function + 패널티 항\n",
    "- Alpha (패널티 항 통제 계수, Hyper Parameter)\n",
    "\n",
    "- Ridge : L2규제(제곱으로 연산되는 패널티 항을 추가) / 상대적으로 큰 회귀 계수값을 통제하여 (회귀 계수를 특정 값 이상으로 커지지 않게 통제) Overfitting이 발생하지 않도록 규제  \n",
    "    - 높은 Alpha : 모델의 계수를 더 많이 축소하여 복잡성을 줄임 (Overfitting방지 / 성능 저하)\n",
    "    - 낮은 Alpha : 정규화 효과를 줄여(패널티를 줄임) 모델의 계수가 더 늘어나게 통제 (Overfitting 발생 가능성)\n",
    "      \n",
    "- Lasso : L1규제(절댓값으로 연산되는 패널티 항을 추가) / 예측 영향력이 적은 X의 회귀 계수를 0으로 만들어 회귀분석에 선택되지 않게 통제 (변수 선택법)\n",
    "    - 제조/공정에서 X Column이 굉장히 많은 경우 -> 유의미한 X를 선택해 남긴 뒤, 다시 회귀 분석을 수행\n",
    "    - 높은 Alpha : 모델의 계수를 더욱 많이 축소, 0으로 변환 (Overfitting방지 / 단순화 / 성능 저하)\n",
    "    - 낮은 Alpha : 모델의 복잡성은 증가 / 0으로 삭제되는 Column은 줄임 (Overfitting발생/ 복잡성)\n",
    "- Elastic : L1 + L2 / 회귀 계수가 큰 인자는 통제, 회귀 계수가 작은 인자는 0으로 만들어 통제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93574da0-eea1-4fb7-8a3e-5e3278497029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4b6f2ef-a17f-4d8c-b52b-113b04aff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = make_pipeline(StandardScaler(), Lasso())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ae8da04-4b40-48e0-a7a6-fe7a1a054148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso HyperParameter Tuning  및 회귀 계수 확인 \n",
    "hyperparameter = {'lasso__alpha':[0.01, 0.1, 1, 1.5, 2]}\n",
    "grid_model = GridSearchCV(model_pipe, param_grid=hyperparameter, cv=3)\n",
    "grid_model.fit(X_train, Y_train)\n",
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a18c953-7f2c-42fe-85e5-72ea258e8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef_lasso = pd.DataFrame()\n",
    "df_coef_lasso['coef'] = best_model['lasso'].coef_\n",
    "df_coef_lasso['X'] = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37594635-2492-422d-8aa0-f5528434f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b635dd2-dc6c-4266-ab7e-db6311af595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge HyperParameter Tuning 및 회귀 계수 확인 \n",
    "model_pipe2  = make_pipeline(StandardScaler(), Ridge())\n",
    "hyperparameter = {'ridge__alpha':[0.01, 0.1, 1, 1.5, 2]}\n",
    "grid_model = GridSearchCV(model_pipe2 , param_grid=hyperparameter, cv=3)\n",
    "grid_model.fit(X_train, Y_train)\n",
    "best_model2 = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b34bd598-f049-461d-8f7e-3d556a333898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef_ridge = pd.DataFrame()\n",
    "df_coef_ridge['coef'] = best_model2['ridge'].coef_\n",
    "df_coef_ridge['X'] = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e8dbd3b-13bf-445d-b0b3-cacf60d5b029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_coef_ridge"
   ]
  },
  {
   "attachments": {
    "0273fad6-64c3-4cbb-a1e1-7740cbed0511.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2d69b506-e5f6-4ff6-b14a-1c34c3923190",
   "metadata": {},
   "source": [
    "# 로지스틱 회귀 분석 (Logistic Regression) \n",
    "\n",
    "- Y 범주형 형태인 분류를 수행할 수 있는 회귀 분석 모델 (분류기법)\n",
    "- 선형회귀 기법 -> 분류 모델\n",
    "- 원리 :\n",
    "    ![image.png](attachment:0273fad6-64c3-4cbb-a1e1-7740cbed0511.png)\n",
    "  - Odds(오즈, 승산) : 임의의 사건이 발생할 확률\n",
    "  - Odds Ratio (오즈 비율, 승산비) : 임의의 특정 사건이 발생하고, 해당 사건에 성공,실패 여부의 비율을 계산\n",
    "  - Odds값을 계산한 뒤, log 함수를 취하여 Link Function(연결함수- 특정함수를 다른 형태로 변화하기 위한 함수/ 로짓 함수 (Log odds))의 선형 예측 모델을 로지스틱 변환을 통해 1,0 (A,B)과 같은 분류를 수행   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ba171-66e8-4871-9112-a4ab2860f1a2",
   "metadata": {},
   "source": [
    "- 시그모이드 (Sigmoid)함수 형태로 연결함수를 최적화 -> 시그모이드 함수의 Y를 분류의 확률 값으로 사용하여 분류를 진행\n",
    "- Logistic Regression 알고리즘의 최적화 기법\n",
    "  - Newton Conjugate Gradient : 뉴턴공액경사기법 / Log odds 함수의 Cost Function을 최소화 하기 위해 사용되는 최적화 함수\n",
    "    - 작동 원리 :\n",
    "         1. 초기 추정값 세팅\n",
    "         2. 비용함수 Cost Function 도함수 계산 / Hessian Matix 헤이시안 행렬 계산을 수행\n",
    "         3. Update 방향을 결정 (Newton 함수를 활용해 Update 방향을 결정)\n",
    "         4. Conjugate Gradient 을 이용하여, 새로운 Update  값을 계산\n",
    "         5. 최적화가 충분히 진행 될 때 까지 (Cost Function이 최소지점을 찾을 때 까지) 위의 과정을 반복\n",
    "    - 대규모 데이터셋에서는 속도가 느림/ 매우 정교하게 Cost Function을 계산 -> 성능이 비교적 좋다\n",
    "    - Overfitting 가능성     \n",
    "  - Limited-memory BFGS (Broyden Fletcher Goldfarbs Shanno)\n",
    "    - 메모리 사용을 최소로 줄이며 연산 최적화 기법 (Logistic Regression 알고리즘의 기본값)\n",
    "  - Stochastic Average Gradient (SAG) :\n",
    "    - 확률적 경사하강법을 적용한 최적화 기법 (Batch 통계량을 계산하여 Cost Function 도출) \n",
    "    - 대규모 데이터셋에 적합하며, 연산속도가 빠르고, 메모리 사용량이 적은 최적화 기법\n",
    "  - Stochastic Average Gradient Descent A--(Saga):\n",
    "    - SAG기법에 규제항(*모델의 복잡도가 줄어듦으로, 성능도 저하될 가능성이 있다)을 추가하여 학습을 수행\n",
    "    - 대규모 데이터 셋에 적용 가능, 빠른 연산 -> Overfitting 사전에 방지  \n",
    "  - lib-linear\n",
    "    - 소규모 데이터셋의 이진분류에서 빠르고 효율적인 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41d60979-f024-4d56-b1a5-0dfcb53b0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('15_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f07f121-1cde-4b74-93ae-8d94132cbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2['수술실패여부']\n",
    "X = df2[['신장','연령','체중','통증기간(월)','환자통증정도']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c75a2696-eae6-4c06-acf2-06a180c3b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09bf164d-1b2a-4937-beb8-0a9b6793fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "067a06d0-023d-414d-9186-61435e850798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = make_pipeline(SimpleImputer(strategy='median'), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5dc4b-73dc-42c8-8fbd-29e7641414c9",
   "metadata": {},
   "source": [
    "- Logistic Regression Hyper Parameter\n",
    "  - solver : 최적화에 사용할 알고리즘을 선택 'newton-cg' / 'lbfgs' / 'sag' / 'saga'\n",
    "  - max_iter : 최적화 알고리즘이 Cost Function을 반복 계산의 최대 횟수 지정 (기본값 100회)\n",
    "  - multi_class : 다중클래스(3개 이상의 분류 값)에 대한 처리방법 지정 / (기본값 'auto')\n",
    "  - random_state : 최적화 알고리즘이 계산을 수행할 때 적용하는 Random State\n",
    "  - class_weight : 이진분류(2개의 분류)에서 비율이 깨진데이터(Imbalanced Data)에 대해 학습 시, 비중에 대한 가중치 부여\n",
    "    - 기본값 None : 클래스에 대한 가중치 없이 학습\n",
    "    - balanced : 비율이 적은 클래스에 가중치를 두며 학습 (Imbalaced Data Sampling과 같은 효과)\n",
    "  - penalty : 규제 방법을 지정 (기본값은 L2 적용/ 'l1', 'l2')\n",
    "  - C : 규제항이 적용되었을 때, 규제의 강도 (Alpha 값의 역수 / 기본값 C = 1 )\n",
    "    - C 값이 작을수록 규제가 강화 (Overfitting 방지)\n",
    "    - C 값이 클수록 규제를 완화 (모델의 복잡성을 높이는 방향 /성능 향샹 / 과적합 발생 가능성) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b887f711-af2f-4678-b86d-3ff63d35807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "352ec450-b33d-465b-9ae3-e8484c819534",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {'logisticregression__solver':[ 'lbfgs', 'sag'], # 2가지\n",
    "                 'logisticregression__max_iter':[100,200,300], # 3가지 \n",
    "                 'logisticregression__class_weight':[None, 'balanced']} # 2가지 => 12가지 \n",
    "grid_model = GridSearchCV(model_pipe, param_grid=hyperparameter, cv=3, n_jobs=-1, scoring='f1') # 12 x 3 = 36 학습 \n",
    "grid_model.fit(X_train, Y_train)\n",
    "best_model = grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "893e7e40-1cdc-4492-a81d-32b2c5a1081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0211667 ,  0.02285335,  0.02328503, -0.01210797,  0.14306661]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "117ff372-bbde-46f2-85b9-3a47b9a3f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef = pd.DataFrame() \n",
    "df_coef['coef'] = best_model['logisticregression'].coef_[0]\n",
    "df_coef['X'] = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00e55747-841a-4add-aa08-20e3878420d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.021167</td>\n",
       "      <td>신장</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022853</td>\n",
       "      <td>연령</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023285</td>\n",
       "      <td>체중</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.012108</td>\n",
       "      <td>통증기간(월)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143067</td>\n",
       "      <td>환자통증정도</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coef        X\n",
       "0 -0.021167       신장\n",
       "1  0.022853       연령\n",
       "2  0.023285       체중\n",
       "3 -0.012108  통증기간(월)\n",
       "4  0.143067   환자통증정도"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef # 회귀 계수의 의미 : 회귀계수가 높을 수록 1 값으로 분류될 확률이 높아진다. \n",
    "# 회귀계수가 높다 : Y값에 매우 밀접한 영향을 주고 있는 인자다 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
